## Model name
XGBoost Regressor

## Example Python code
import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split
from sklearn.metrics import mean_squared_error
import xgboost as xgb

# --- 1. Generate dummy data for demonstration ---
X = pd.DataFrame(np.random.rand(1000, 10), columns=[f'feature_{i}' for i in range(10)])
y = pd.Series(np.random.rand(1000) * 100000 + 50000)

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# --- 2. Initialize and Train XGBoost Regressor ---
# objective='reg:squarederror' is standard for regression problems, minimizing squared error.
# eval_metric='rmse' explicitly sets the evaluation metric to RMSE.
model = xgb.XGBRegressor(objective='reg:squarederror', eval_metric='rmse', random_state=42)
model.fit(X_train, y_train)

# --- 3. Make Predictions ---
y_pred = model.predict(X_test)

# --- 4. Evaluate the Model (RMSE) ---
rmse = np.sqrt(mean_squared_error(y_test, y_pred))
print(f"XGBoost RMSE: {rmse:.4f}")
