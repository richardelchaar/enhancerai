## Model name
LightGBM Regressor

## Example Python code
import lightgbm as lgb
import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.metrics import mean_squared_error
import numpy as np

# Sample Data (replace with your actual data loading)
# For demonstration, creating dummy data similar to housing price prediction
np.random.seed(42)
X = pd.DataFrame(np.random.rand(1000, 10), columns=[f'feature_{i}' for i in range(10)])
y = pd.Series(np.random.rand(1000) * 1000000 + 50000, name='median_house_value')

# Split data into training and testing sets
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Initialize LightGBM Regressor
# Common parameters for regression:
# objective='regression' or 'regression_l1' for MAE, 'regression_l2' for MSE
# metric='rmse' for Root Mean Squared Error evaluation
# n_estimators: Number of boosting rounds
# learning_rate: Step size shrinkage to prevent overfitting
# num_leaves: Max number of leaves in one tree
model_lgb = lgb.LGBMRegressor(objective='regression_l2', metric='rmse', n_estimators=1000, learning_rate=0.05, num_leaves=31, random_state=42)

# Train the model
model_lgb.fit(X_train, y_train)

# Make predictions on the test set
y_pred_lgb = model_lgb.predict(X_test)

# Evaluate the model using RMSE
rmse_lgb = np.sqrt(mean_squared_error(y_test, y_pred_lgb))
print(f'LightGBM RMSE: {rmse_lgb:.2f}')